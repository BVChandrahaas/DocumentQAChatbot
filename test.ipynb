{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvcha\\Desktop\\DocumetQA\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bvcha\\Desktop\\DocumetQA\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "\n",
    "def load_and_chunk_document(file_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Load and split the document into overlapping chunks.\n",
    "    \"\"\"\n",
    "    print(\"Loading and chunking document...\")\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Document split into {len(chunks)} chunks.\")\n",
    "    return chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and chunking document...\n",
      "Document split into 4 chunks.\n",
      "[Document(metadata={'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}, page_content='B.V.CHANDRAHAAS\\nNellore, Andhra Pradesh\\n♂phone+91 7993577106 /envel⌢pebvchandrahaas@gmail.com /linkedinlinkedin.com/in/bvchandrahaas /githubgithub.com/BVChandrahaas\\nEducation\\nVellore Institute of Technology Sep 2020 – May 2024\\nB.Tech[ CSE with Spec. in Data Analytics] — CGPA: 8.52 Amaravati, Andhra Pradesh\\nSri Chaitanya Junior Kalasala June 2018 – Mar 2020\\nClass 12, MPC, TSBIE — 87.4 % Hyderabad, Telangana\\nSri Chaitanya Techno School Mar 2018\\nClass 10, TS.SSC — CGPA: 9.5 Hyderabad, Telangana\\nRelevant Coursework\\n• Data Structures\\n• Machine Learning\\n• DBMS\\n• Neural Networks\\n• Artificial Intelligence\\n• Deep Learning\\n• Software Engineering\\n• NLP\\nProjects\\nDeciphering the growing popularity of laptops Jan 2021\\n• Collected Data from 200 users aged between 18 to 51.\\n• Performed Visual analysis and obtained key insights.\\nA Study on Eye wear purchases from Lenskart Oct 2022\\n• Conducted comprehensive marketing research project, leveraging data from Lenskart users.'), Document(metadata={'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}, page_content='• Performed Visual analysis and obtained key insights.\\nA Study on Eye wear purchases from Lenskart Oct 2022\\n• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\\n• conducted visual analysis to identify key drivers of customer satisfaction, resulting in actionable insights.\\nUnveiling Credit Card Fraud using Machine Learning Nov 2022\\n• Ensembled Traditional Machine Learning Algorithms.\\n• Obtained 98% Accuracy over a dataset consisting of 13000 instances and 10 attributes.\\nAI Powered Tool for Dumb and Deaf June 2023\\n• A Project focused on converting hand gestures into text using tailored CNN\\n• Designed a user friendly interface using Gradio to enhance the user experience\\nSynapsys - Leveraging the art of video summarization Nov 2023\\n• A Project focused on summarizing videos using State-of-the-art generative AI models\\nA System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024'), Document(metadata={'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}, page_content='• A Project focused on summarizing videos using State-of-the-art generative AI models\\nA System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\\n• Proposed a new Ensemble framework of DNN’s and Meta Learning resulting in an accuracy of 98%.\\nTechnical Skills\\nProgramming Languages: Python, Java, R, HTML/CSS, SQL\\nDeveloper Tools: VS Code, Eclipse, Google Colab, Jupyter Notebook\\nFrameworks: Tensorflow, Keras, Scikit-learn, Transformers, NLTK\\nLibraries: pandas, Numpy, Matplotlib, Seaborn, ggplot2\\nPublications\\nAn Empirical Study on Classification of Monkeypox Skin Lesion Detection December 2022\\n∗ Published in EAI endorsed transactions of Pervasive Health and Technology.\\n∗ Recieved Honorary Raman Research Award from University\\nA Hybrid Approach for Mobile Phone Recommendation using Content & Collaborative Filtering July 2023\\n∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI'), Document(metadata={'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}, page_content='∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI\\n2) Introduction to Data Analytics\\n3) SmartBridge AI Externship Program\\n4) Summer Analytics By IIT Guwahati\\n5) Data Science and Advanced Analytics Tools')]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf\"\n",
    "print(load_and_chunk_document(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_and_store(chunks):\n",
    "    \"\"\"\n",
    "    Generate embeddings for chunks and store in FAISS.\n",
    "    \"\"\"\n",
    "    print(\"Generating embeddings and storing in FAISS...\")\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "    embedding_dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    metadata = [{\"text\": chunk.page_content, \"metadata\": chunk.metadata} for chunk in chunks]\n",
    "    print(\"Embeddings generated and stored successfully.\")\n",
    "    return index, metadata, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and chunking document...\n",
      "Document split into 4 chunks.\n",
      "Generating embeddings and storing in FAISS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated and stored successfully.\n",
      "(<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x000001D670B57FC0> >, [{'text': 'B.V.CHANDRAHAAS\\nNellore, Andhra Pradesh\\n♂phone+91 7993577106 /envel⌢pebvchandrahaas@gmail.com /linkedinlinkedin.com/in/bvchandrahaas /githubgithub.com/BVChandrahaas\\nEducation\\nVellore Institute of Technology Sep 2020 – May 2024\\nB.Tech[ CSE with Spec. in Data Analytics] — CGPA: 8.52 Amaravati, Andhra Pradesh\\nSri Chaitanya Junior Kalasala June 2018 – Mar 2020\\nClass 12, MPC, TSBIE — 87.4 % Hyderabad, Telangana\\nSri Chaitanya Techno School Mar 2018\\nClass 10, TS.SSC — CGPA: 9.5 Hyderabad, Telangana\\nRelevant Coursework\\n• Data Structures\\n• Machine Learning\\n• DBMS\\n• Neural Networks\\n• Artificial Intelligence\\n• Deep Learning\\n• Software Engineering\\n• NLP\\nProjects\\nDeciphering the growing popularity of laptops Jan 2021\\n• Collected Data from 200 users aged between 18 to 51.\\n• Performed Visual analysis and obtained key insights.\\nA Study on Eye wear purchases from Lenskart Oct 2022\\n• Conducted comprehensive marketing research project, leveraging data from Lenskart users.', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '• Performed Visual analysis and obtained key insights.\\nA Study on Eye wear purchases from Lenskart Oct 2022\\n• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\\n• conducted visual analysis to identify key drivers of customer satisfaction, resulting in actionable insights.\\nUnveiling Credit Card Fraud using Machine Learning Nov 2022\\n• Ensembled Traditional Machine Learning Algorithms.\\n• Obtained 98% Accuracy over a dataset consisting of 13000 instances and 10 attributes.\\nAI Powered Tool for Dumb and Deaf June 2023\\n• A Project focused on converting hand gestures into text using tailored CNN\\n• Designed a user friendly interface using Gradio to enhance the user experience\\nSynapsys - Leveraging the art of video summarization Nov 2023\\n• A Project focused on summarizing videos using State-of-the-art generative AI models\\nA System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '• A Project focused on summarizing videos using State-of-the-art generative AI models\\nA System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\\n• Proposed a new Ensemble framework of DNN’s and Meta Learning resulting in an accuracy of 98%.\\nTechnical Skills\\nProgramming Languages: Python, Java, R, HTML/CSS, SQL\\nDeveloper Tools: VS Code, Eclipse, Google Colab, Jupyter Notebook\\nFrameworks: Tensorflow, Keras, Scikit-learn, Transformers, NLTK\\nLibraries: pandas, Numpy, Matplotlib, Seaborn, ggplot2\\nPublications\\nAn Empirical Study on Classification of Monkeypox Skin Lesion Detection December 2022\\n∗ Published in EAI endorsed transactions of Pervasive Health and Technology.\\n∗ Recieved Honorary Raman Research Award from University\\nA Hybrid Approach for Mobile Phone Recommendation using Content & Collaborative Filtering July 2023\\n∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI\\n2) Introduction to Data Analytics\\n3) SmartBridge AI Externship Program\\n4) Summer Analytics By IIT Guwahati\\n5) Data Science and Advanced Analytics Tools', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}], SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      "))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = load_and_chunk_document(file_path)\n",
    "print(generate_embeddings_and_store(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings and storing in FAISS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated and stored successfully.\n",
      "Retrieving relevant chunks...\n",
      "DEBUG - Chunk 1: B.V.CHANDRAHAAS\n",
      "Nellore, Andhra Pradesh\n",
      "♂phone+91 7993577106 /envel⌢pebvchandrahaas@gmail.com /linkedinlinkedin.com/in/bvchandrahaas /githubgithub.com/BVChandrahaas\n",
      "Education\n",
      "Vellore Institute of Tech...\n",
      "DEBUG - Chunk 2: • Performed Visual analysis and obtained key insights.\n",
      "A Study on Eye wear purchases from Lenskart Oct 2022\n",
      "• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\n",
      "•...\n",
      "DEBUG - Chunk 3: ∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "2) Introduction to Data Analytics\n",
      "3) SmartBridge AI Externship Program\n",
      "4) Summer ...\n",
      "DEBUG - Chunk 4: • A Project focused on summarizing videos using State-of-the-art generative AI models\n",
      "A System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\n",
      "• Proposed a new Ensemble frame...\n",
      "DEBUG - Chunk 5: ∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "2) Introduction to Data Analytics\n",
      "3) SmartBridge AI Externship Program\n",
      "4) Summer ...\n",
      "[{'text': 'B.V.CHANDRAHAAS\\nNellore, Andhra Pradesh\\n♂phone+91 7993577106 /envel⌢pebvchandrahaas@gmail.com /linkedinlinkedin.com/in/bvchandrahaas /githubgithub.com/BVChandrahaas\\nEducation\\nVellore Institute of Technology Sep 2020 – May 2024\\nB.Tech[ CSE with Spec. in Data Analytics] — CGPA: 8.52 Amaravati, Andhra Pradesh\\nSri Chaitanya Junior Kalasala June 2018 – Mar 2020\\nClass 12, MPC, TSBIE — 87.4 % Hyderabad, Telangana\\nSri Chaitanya Techno School Mar 2018\\nClass 10, TS.SSC — CGPA: 9.5 Hyderabad, Telangana\\nRelevant Coursework\\n• Data Structures\\n• Machine Learning\\n• DBMS\\n• Neural Networks\\n• Artificial Intelligence\\n• Deep Learning\\n• Software Engineering\\n• NLP\\nProjects\\nDeciphering the growing popularity of laptops Jan 2021\\n• Collected Data from 200 users aged between 18 to 51.\\n• Performed Visual analysis and obtained key insights.\\nA Study on Eye wear purchases from Lenskart Oct 2022\\n• Conducted comprehensive marketing research project, leveraging data from Lenskart users.', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '• Performed Visual analysis and obtained key insights.\\nA Study on Eye wear purchases from Lenskart Oct 2022\\n• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\\n• conducted visual analysis to identify key drivers of customer satisfaction, resulting in actionable insights.\\nUnveiling Credit Card Fraud using Machine Learning Nov 2022\\n• Ensembled Traditional Machine Learning Algorithms.\\n• Obtained 98% Accuracy over a dataset consisting of 13000 instances and 10 attributes.\\nAI Powered Tool for Dumb and Deaf June 2023\\n• A Project focused on converting hand gestures into text using tailored CNN\\n• Designed a user friendly interface using Gradio to enhance the user experience\\nSynapsys - Leveraging the art of video summarization Nov 2023\\n• A Project focused on summarizing videos using State-of-the-art generative AI models\\nA System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI\\n2) Introduction to Data Analytics\\n3) SmartBridge AI Externship Program\\n4) Summer Analytics By IIT Guwahati\\n5) Data Science and Advanced Analytics Tools', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '• A Project focused on summarizing videos using State-of-the-art generative AI models\\nA System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\\n• Proposed a new Ensemble framework of DNN’s and Meta Learning resulting in an accuracy of 98%.\\nTechnical Skills\\nProgramming Languages: Python, Java, R, HTML/CSS, SQL\\nDeveloper Tools: VS Code, Eclipse, Google Colab, Jupyter Notebook\\nFrameworks: Tensorflow, Keras, Scikit-learn, Transformers, NLTK\\nLibraries: pandas, Numpy, Matplotlib, Seaborn, ggplot2\\nPublications\\nAn Empirical Study on Classification of Monkeypox Skin Lesion Detection December 2022\\n∗ Published in EAI endorsed transactions of Pervasive Health and Technology.\\n∗ Recieved Honorary Raman Research Award from University\\nA Hybrid Approach for Mobile Phone Recommendation using Content & Collaborative Filtering July 2023\\n∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}, {'text': '∗ Published in EAI endorsed transactions of IOT.\\nCertifications\\n1) Oracle Cloud Infrastructure Certified Generative AI\\n2) Introduction to Data Analytics\\n3) SmartBridge AI Externship Program\\n4) Summer Analytics By IIT Guwahati\\n5) Data Science and Advanced Analytics Tools', 'metadata': {'source': 'C://Users//bvcha//Desktop//DocumetQA//uploaded_pdfs//BVCHANDRAHAAS_RESUME.pdf', 'page': 0}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index,metadata,model = generate_embeddings_and_store(chunks)\n",
    "query = \"Tell me about India \"\n",
    "def retrieve_relevant_chunks(index, metadata, query, model, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve the most relevant chunks using FAISS and query embeddings.\n",
    "    \"\"\"\n",
    "    print(\"Retrieving relevant chunks...\")\n",
    "    query_embedding = model.encode([query])\n",
    "    distances, indices = index.search(query_embedding, k=k)\n",
    "\n",
    "    # Fetch metadata for the top results\n",
    "    retrieved_docs = [metadata[idx] for idx in indices[0]]\n",
    "\n",
    "    # Debug: Print retrieved chunks\n",
    "    for idx, doc in enumerate(retrieved_docs):\n",
    "        print(f\"DEBUG - Chunk {idx + 1}: {doc['text'][:200]}...\")\n",
    "    return retrieved_docs\n",
    "print(retrieve_relevant_chunks(index,metadata,query,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving relevant chunks...\n",
      "DEBUG - Chunk 1: B.V.CHANDRAHAAS\n",
      "Nellore, Andhra Pradesh\n",
      "♂phone+91 7993577106 /envel⌢pebvchandrahaas@gmail.com /linkedinlinkedin.com/in/bvchandrahaas /githubgithub.com/BVChandrahaas\n",
      "Education\n",
      "Vellore Institute of Tech...\n",
      "DEBUG - Chunk 2: • Performed Visual analysis and obtained key insights.\n",
      "A Study on Eye wear purchases from Lenskart Oct 2022\n",
      "• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\n",
      "•...\n",
      "DEBUG - Chunk 3: ∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "2) Introduction to Data Analytics\n",
      "3) SmartBridge AI Externship Program\n",
      "4) Summer ...\n",
      "DEBUG - Chunk 4: • A Project focused on summarizing videos using State-of-the-art generative AI models\n",
      "A System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\n",
      "• Proposed a new Ensemble frame...\n",
      "DEBUG - Chunk 5: ∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "2) Introduction to Data Analytics\n",
      "3) SmartBridge AI Externship Program\n",
      "4) Summer ...\n",
      "Chunk 1:\n",
      "B.V.CHANDRAHAAS\n",
      "Nellore, Andhra Pradesh\n",
      "♂phone+91 7993577106 /envel⌢pebvchandrahaas@gmail.com /linkedinlinkedin.com/in/bvchandrahaas /githubgithub.com/BVChandrahaas\n",
      "Education\n",
      "Vellore Institute of Technology Sep 2020 – May 2024\n",
      "B.Tech[ CSE with Spec. in Data Analytics] — CGPA: 8.52 Amaravati, Andhra Pradesh\n",
      "Sri Chaitanya Junior Kalasala June 2018 – Mar 2020\n",
      "Class 12, MPC, TSBIE — 87.4 % Hyderabad, Telangana\n",
      "Sri Chaitanya Techno School Mar 2018\n",
      "Class 10, TS.SSC — CGPA: 9.5 Hyderabad, Telangana\n",
      "Relevant Coursework\n",
      "• Data Structures\n",
      "• Machine Learning\n",
      "• DBMS\n",
      "• Neural Networks\n",
      "• Artificial Intelligence\n",
      "• Deep Learning\n",
      "• Software Engineering\n",
      "• NLP\n",
      "Projects\n",
      "Deciphering the growing popularity of laptops Jan 2021\n",
      "• Collected Data from 200 users aged between 18 to 51.\n",
      "• Performed Visual analysis and obtained key insights.\n",
      "A Study on Eye wear purchases from Lenskart Oct 2022\n",
      "• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\n",
      "\n",
      "Chunk 2:\n",
      "• Performed Visual analysis and obtained key insights.\n",
      "A Study on Eye wear purchases from Lenskart Oct 2022\n",
      "• Conducted comprehensive marketing research project, leveraging data from Lenskart users.\n",
      "• conducted visual analysis to identify key drivers of customer satisfaction, resulting in actionable insights.\n",
      "Unveiling Credit Card Fraud using Machine Learning Nov 2022\n",
      "• Ensembled Traditional Machine Learning Algorithms.\n",
      "• Obtained 98% Accuracy over a dataset consisting of 13000 instances and 10 attributes.\n",
      "AI Powered Tool for Dumb and Deaf June 2023\n",
      "• A Project focused on converting hand gestures into text using tailored CNN\n",
      "• Designed a user friendly interface using Gradio to enhance the user experience\n",
      "Synapsys - Leveraging the art of video summarization Nov 2023\n",
      "• A Project focused on summarizing videos using State-of-the-art generative AI models\n",
      "A System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\n",
      "\n",
      "Chunk 3:\n",
      "∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "2) Introduction to Data Analytics\n",
      "3) SmartBridge AI Externship Program\n",
      "4) Summer Analytics By IIT Guwahati\n",
      "5) Data Science and Advanced Analytics Tools\n",
      "\n",
      "Chunk 4:\n",
      "• A Project focused on summarizing videos using State-of-the-art generative AI models\n",
      "A System and Method for Multi-Class Paddy Disease Detection using MLOps April 2024\n",
      "• Proposed a new Ensemble framework of DNN’s and Meta Learning resulting in an accuracy of 98%.\n",
      "Technical Skills\n",
      "Programming Languages: Python, Java, R, HTML/CSS, SQL\n",
      "Developer Tools: VS Code, Eclipse, Google Colab, Jupyter Notebook\n",
      "Frameworks: Tensorflow, Keras, Scikit-learn, Transformers, NLTK\n",
      "Libraries: pandas, Numpy, Matplotlib, Seaborn, ggplot2\n",
      "Publications\n",
      "An Empirical Study on Classification of Monkeypox Skin Lesion Detection December 2022\n",
      "∗ Published in EAI endorsed transactions of Pervasive Health and Technology.\n",
      "∗ Recieved Honorary Raman Research Award from University\n",
      "A Hybrid Approach for Mobile Phone Recommendation using Content & Collaborative Filtering July 2023\n",
      "∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "\n",
      "Chunk 5:\n",
      "∗ Published in EAI endorsed transactions of IOT.\n",
      "Certifications\n",
      "1) Oracle Cloud Infrastructure Certified Generative AI\n",
      "2) Introduction to Data Analytics\n",
      "3) SmartBridge AI Externship Program\n",
      "4) Summer Analytics By IIT Guwahati\n",
      "5) Data Science and Advanced Analytics Tools\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retrieve_relevant_chunks(index,metadata,query,model)\n",
    "def combine_chunks(retrieved_docs):\n",
    "    \"\"\"\n",
    "    Combine chunks into a single string with proper structure.\n",
    "    \"\"\"\n",
    "    combined_context = \"\"\n",
    "    for idx, doc in enumerate(retrieved_docs):\n",
    "        text = doc.get(\"text\", \"\").strip()\n",
    "        if text:\n",
    "            combined_context += f\"Chunk {idx + 1}:\\n{text}\\n\\n\"\n",
    "    return combined_context\n",
    "combined_context = combine_chunks(retrieved_docs)\n",
    "print(combined_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I do not know the answer based on the provided context.\n"
     ]
    }
   ],
   "source": [
    "context = combined_context\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def generate_answer(context, query):\n",
    "    \"\"\"\n",
    "    Generate an answer using OpenAI GPT-4 chat model.\n",
    "    If the context doesn't have an answer, the model replies accordingly.\n",
    "    \"\"\"\n",
    "    # Define the chat-based prompt template\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are a document assistant. Use only the information in the provided context to answer the question.\n",
    "        If the context does not contain the answer, reply: \n",
    "        \"I'm sorry, I do not know the answer based on the provided context.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Initialize the ChatOpenAI model\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4, openai_api_key=\"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\")\n",
    "\n",
    "    # Format the prompt\n",
    "    formatted_prompt = prompt.format(context=context, question=query)\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    return response.content\n",
    "print(generate_answer(context,query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
